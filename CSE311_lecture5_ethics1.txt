0:0:0.0 --> 0:0:3.750
Hawthorne, Matthew
So probably doesn't matter too much, so OK.
0:0:13.850 --> 0:0:14.820
Hawthorne, Matthew
Thank you, Robert.
0:0:14.870 --> 0:0:16.180
Hawthorne, Matthew
You just started the recording.
0:0:16.460 --> 0:0:18.360
Hawthorne, Matthew
I appreciate that I had forgotten to do so.
0:0:18.670 --> 0:0:19.680
Hawthorne, Matthew
I'm off my schedule.
0:0:19.790 --> 0:0:25.360
Hawthorne, Matthew
It's way it goes, so let me before I get started with the class time.
0:0:25.370 --> 0:0:27.30
Hawthorne, Matthew
I do want to just talk to you all about this.
0:0:27.550 --> 0:0:28.140
Hawthorne, Matthew
Umm.
0:0:28.770 --> 0:0:36.840
Hawthorne, Matthew
I teach solo 6 classes, 3 ethics classes, and three copyright classes for each class.
0:0:37.50 --> 0:0:46.600
Hawthorne, Matthew
I judge participation both by reviewing the meeting chat, because most people tend to, you know, it's one of the benefits to doing this.
0:0:46.690 --> 0:0:50.600
Hawthorne, Matthew
But with this format is you all can talk all you want.
0:0:50.610 --> 0:0:55.100
Hawthorne, Matthew
Ask questions in the meeting chat and that's how most class participation handles.
0:0:55.330 --> 0:0:59.400
Hawthorne, Matthew
But then I also do the blackboard discussion questions.
0:1:2.260 --> 0:1:5.350
Hawthorne, Matthew
And I do ask that you all do respond to these.
0:1:5.360 --> 0:1:14.330
Hawthorne, Matthew
I do read all of them every once in a while, I'll respond when someone raises a point that I think needs some response, or when someone like tries, you know, ask me a question on them.
0:1:14.900 --> 0:1:18.30
Hawthorne, Matthew
But I do encourage you all to put your thoughts there.
0:1:18.120 --> 0:1:24.90
Hawthorne, Matthew
They basically act as little like participation quizzes to make certain that you all were paying a modicum of attention.
0:1:24.100 --> 0:1:25.370
Hawthorne, Matthew
I don't have high expectations.
0:1:25.380 --> 0:1:26.940
Hawthorne, Matthew
It's a. It's a.
0:1:27.610 --> 0:1:31.620
Hawthorne, Matthew
It's a I forget what it's called, but it's a it's a.
0:1:32.70 --> 0:1:39.980
Hawthorne, Matthew
It's a remote class at the you know it's a live remote class, so I know how these things go, but this is this is the way that I track participation.
0:1:40.210 --> 0:1:45.250
Hawthorne, Matthew
The other thing is is we do do an ethics directed grade.
0:1:45.530 --> 0:1:53.150
Hawthorne, Matthew
In the past I had done an ethics paper, but I had a couple semesters ago I switched that to an ethics essay test.
0:1:54.170 --> 0:1:54.850
Hawthorne, Matthew
UM.
0:1:55.850 --> 0:2:5.420
Hawthorne, Matthew
So unless and, that's been working pretty well, it's it's a little less work on you all and it's still, I mean it's it's an essay test on Blackboard.
0:2:5.430 --> 0:2:9.880
Hawthorne, Matthew
You have, I think I assigned it and you have a week to do it or something like that.
0:2:10.450 --> 0:2:12.680
Hawthorne, Matthew
That'll be after my last ethics class.
0:2:12.690 --> 0:2:21.540
Hawthorne, Matthew
So unless I hear from a decent number of you that you would really like to do in ethics paper instead, I'm just gonna keep doing that.
0:2:21.870 --> 0:2:27.370
Hawthorne, Matthew
The one benefit to the ethics paper is you do get a pick your own topic, whereas with the it's a test.
0:2:27.380 --> 0:2:33.70
Hawthorne, Matthew
I've just got a, you know, a genericized fact pattern that I asked you to write an essay about.
0:2:33.80 --> 0:2:36.90
Hawthorne, Matthew
It's it's kind of, it's like a law school test.
0:2:36.100 --> 0:2:37.550
Hawthorne, Matthew
Only way less intense.
0:2:38.160 --> 0:2:45.830
Hawthorne, Matthew
Umm, so do keep that in mind and if like is it if some of you all would actually like to write a paper, let me know.
0:2:48.30 --> 0:2:56.940
Hawthorne, Matthew
Believe it or not, I always have a few people that would prefer that option, so I'm open to it, but it's gonna be one thing for everybody.
0:2:56.950 --> 0:3:0.460
Hawthorne, Matthew
I can't be doing, you know, different, different ethics grades for everybody.
0:3:1.160 --> 0:3:3.260
Hawthorne, Matthew
And it is a substantial part of your grade.
0:3:4.70 --> 0:3:5.620
Hawthorne, Matthew
I'm not exactly a difficult grader.
0:3:7.60 --> 0:3:12.800
Hawthorne, Matthew
Migrating scale is as long as you answer the question with like you know, a modicum of effort.
0:3:12.810 --> 0:3:17.390
Hawthorne, Matthew
You're probably gonna get B if you don't answer questions I take off.
0:3:17.480 --> 0:3:29.830
Hawthorne, Matthew
If you do answer questions, you know if you answer questions thoroughly, you get bumped up, and then if you're really like if you're really doing a good job, you know if you're wrapping in things we discussed in class.
0:3:29.840 --> 0:3:36.960
Hawthorne, Matthew
If you're wrapping in external sources, if you're making really good points, I could tell you're really thinking about it.
0:3:38.310 --> 0:3:42.890
Hawthorne, Matthew
That's how you get an A on the ethics ethics test or the ethics paper, depending on how we do it.
0:3:45.180 --> 0:3:53.410
Hawthorne, Matthew
So but if you have any any questions about the scale, the grading criteria when we get closer to the test, I'll be happy to answer those.
0:3:53.800 --> 0:3:59.780
Hawthorne, Matthew
So all of that stuff aside, let me pull up the slides and start presenting on these.
0:4:5.340 --> 0:4:5.810
Hawthorne, Matthew
There it is.
0:4:17.530 --> 0:4:18.670
Hawthorne, Matthew
So that should be.
0:4:20.330 --> 0:4:22.210
Hawthorne, Matthew
Should be working now you all see in the slides.
0:4:26.390 --> 0:4:28.130
Hawthorne, Matthew
Umm, OK.
0:4:28.140 --> 0:4:28.960
Hawthorne, Matthew
This is gonna be a problem.
0:4:36.670 --> 0:4:37.340
Hawthorne, Matthew
Sorry folks.
0:4:37.350 --> 0:4:41.280
Hawthorne, Matthew
My it's just a just a add on my.
0:4:44.500 --> 0:4:48.750
Hawthorne, Matthew
Second Monitor isn't working right now, so I'm having to figure out how to be able to see the.
0:4:53.50 --> 0:4:57.680
Hawthorne, Matthew
See the slides and you're all chatting at the same time.
0:4:58.250 --> 0:5:1.710
Hawthorne, Matthew
Uh may not be able to let me just have to back and forth a bunch.
0:5:4.170 --> 0:5:4.610
Hawthorne, Matthew
That's fine.
0:5:5.740 --> 0:5:6.470
Hawthorne, Matthew
I can deal with it.
0:5:9.220 --> 0:5:10.680
Hawthorne, Matthew
I'd appreciate confirming that.
0:5:12.870 --> 0:5:14.10
Hawthorne, Matthew
Alright, so let's get this started.
0:5:20.410 --> 0:5:21.600
Hawthorne, Matthew
All right, so here we go.
0:5:21.990 --> 0:5:22.940
Hawthorne, Matthew
Ethics.
0:5:23.270 --> 0:5:24.190
Hawthorne, Matthew
Ethics is awesome.
0:5:26.800 --> 0:5:27.780
Hawthorne, Matthew
Oh, this is the wrong slide.
0:5:31.230 --> 0:5:31.840
Hawthorne, Matthew
Sorry folks.
0:5:31.850 --> 0:5:35.390
Hawthorne, Matthew
Again, I'm a little little little out of sorts.
0:5:35.400 --> 0:5:37.730
Hawthorne, Matthew
Today I clicked on the wrong slide.
0:5:41.810 --> 0:5:42.340
Hawthorne, Matthew
There we go.
0:5:42.350 --> 0:5:43.190
Hawthorne, Matthew
Now I've got the right one.
0:5:53.10 --> 0:5:54.60
Hawthorne, Matthew
There we go.
0:5:54.530 --> 0:5:55.520
Hawthorne, Matthew
Introduction to ethics.
0:5:55.530 --> 0:5:55.830
Hawthorne, Matthew
Yes, yes.
0:6:2.220 --> 0:6:2.440
Hawthorne, Matthew
OK.
0:6:7.260 --> 0:6:9.230
Hawthorne, Matthew
Alright, introduction to ethics.
0:6:9.300 --> 0:6:11.880
Hawthorne, Matthew
Question #1 cause philosophy class.
0:6:11.890 --> 0:6:14.310
Hawthorne, Matthew
At this point, folks, so we ask a lot of questions in here.
0:6:14.380 --> 0:6:17.170
Hawthorne, Matthew
So what is ethics and what isn't ethics?
0:6:18.60 --> 0:6:19.630
Hawthorne, Matthew
What are your all thoughts on that?
0:6:19.690 --> 0:6:20.510
Hawthorne, Matthew
Feel free to chat.
0:6:20.800 --> 0:6:21.340
Hawthorne, Matthew
It into the chat.
0:6:24.940 --> 0:6:31.110
Hawthorne, Matthew
I will tell you they are very few wrong answers and there are a whole lot of right answers to these sorts of questions.
0:6:31.420 --> 0:6:33.250
Hawthorne, Matthew
So Austin says study of morality.
0:6:33.260 --> 0:6:37.350
Hawthorne, Matthew
That is a correct answer, Sean doing the right thing when no one is looking at.
0:6:37.360 --> 0:6:41.950
Hawthorne, Matthew
It's more integrity, morals and principle that is a correct answer.
0:6:42.580 --> 0:6:44.780
Hawthorne, Matthew
Her Phillip a code of moral principles.
0:6:44.790 --> 0:6:46.510
Hawthorne, Matthew
That's good framework.
0:6:46.560 --> 0:6:55.180
Hawthorne, Matthew
Joey Framework study of how to make moral choices ohm that is a very good answer as is Nicholas's there.
0:6:55.190 --> 0:6:56.40
Hawthorne, Matthew
Ethics is conduct.
0:6:56.50 --> 0:6:57.980
Hawthorne, Matthew
Morality is metaphysical.
0:7:0.580 --> 0:7:1.890
Hawthorne, Matthew
Moral I Ben.
0:7:1.900 --> 0:7:9.280
Hawthorne, Matthew
I like that answer a moral Rubik to Drudge Judge actions by those are all those are all very good answers.
0:7:12.440 --> 0:7:14.370
Hawthorne, Matthew
No one in there had a wrong answer.
0:7:15.280 --> 0:7:17.710
Hawthorne, Matthew
So yeah, those are all things.
0:7:17.800 --> 0:7:24.40
Hawthorne, Matthew
All of that is ethics, so the second question is, is what isn't ethics Jacob?
0:7:24.50 --> 0:7:26.690
Hawthorne, Matthew
That's a relativistic and good point.
0:7:27.770 --> 0:7:31.520
Hawthorne, Matthew
Uh, Richard, you said there think there's a distinction between morality and ethics.
0:7:31.530 --> 0:7:33.140
Hawthorne, Matthew
All actually get into that in just a minute.
0:7:33.150 --> 0:7:36.410
Hawthorne, Matthew
There is, but there also isn't, because again, philosophy.
0:7:38.70 --> 0:7:41.70
Hawthorne, Matthew
And who's says ethics is not ones personal belief.
0:7:41.130 --> 0:7:47.540
Hawthorne, Matthew
Umm yes, but also no umm, because individual ethics is a thing.
0:7:51.70 --> 0:7:52.900
Hawthorne, Matthew
At so Philip, you are correct.
0:7:52.910 --> 0:7:55.0
Hawthorne, Matthew
Ethics potentially are not objective.
0:7:55.90 --> 0:8:3.340
Hawthorne, Matthew
There is such a thing as subjective ethics, and whether that's a strength or a weakness, you know, kind of depends on your viewpoint and what you're using them for.
0:8:3.510 --> 0:8:12.140
Hawthorne, Matthew
I tend to view it as a weakness, so that is actually one of the criticisms of one of the major forms of ethics.
0:8:12.150 --> 0:8:12.710
Hawthorne, Matthew
We'll talk about.
0:8:19.910 --> 0:8:23.120
Hawthorne, Matthew
It's always tougher to answer negative, but you all did a good attempt at it.
0:8:23.190 --> 0:8:28.60
Hawthorne, Matthew
One of the things I like to emphasize is ethics is not necessarily law.
0:8:28.530 --> 0:8:30.90
Hawthorne, Matthew
Ethics isn't necessarily.
0:8:32.870 --> 0:8:33.760
Hawthorne, Matthew
Morality.
0:8:33.810 --> 0:8:39.310
Hawthorne, Matthew
Someone mentioned that Richard you were mentioning that there's a distinction between morality and ethics.
0:8:39.550 --> 0:8:44.700
Hawthorne, Matthew
A lot of these things are interrelated, but not necessarily the same.
0:8:46.300 --> 0:9:5.860
Hawthorne, Matthew
So when we just talk about ethics in this class, we are using the basically the Internet and cyclopedia of philosophy definition which is systemizing defending and recommending concepts of right and wrong behavior behavior in this case is both actions and decisions.
0:9:6.210 --> 0:9:11.340
Hawthorne, Matthew
But you see the Merriam-webster simple definition, you know, there you go.
0:9:17.500 --> 0:9:30.250
Hawthorne, Matthew
The there are but interesting thing here is there's three major categories of ethics, you know, and the first major category which we are not going to cover in class very much is called metaethics.
0:9:30.380 --> 0:9:34.550
Hawthorne, Matthew
And that is where you're getting into like the fundamental questions of morality.
0:9:34.620 --> 0:9:36.10
Hawthorne, Matthew
What is good?
0:9:36.60 --> 0:9:37.600
Hawthorne, Matthew
What is evil?
0:9:37.760 --> 0:9:42.330
Hawthorne, Matthew
You know, is there such a thing as intrinsic good and intrinsic evil?
0:9:42.340 --> 0:9:44.440
Hawthorne, Matthew
Are they merely extrinsic factors?
0:9:45.890 --> 0:9:52.320
Hawthorne, Matthew
You know, so yes, ethics is morality, but for us, no, ethics is not morality.
0:9:52.410 --> 0:9:59.500
Hawthorne, Matthew
And we do that mostly because that sort of stuff is really hard to talk about, right?
0:9:59.570 --> 0:10:15.260
Hawthorne, Matthew
That's the sort of thing where either you're talking about people's like, closely held religious beliefs and you gotta be very careful about those sorts of conversations or you're just you're engaging in the sorts of discussions that involve, like reams of really dense paper, right.
0:10:15.750 --> 0:10:26.620
Hawthorne, Matthew
And it's the sort of thing where those are the good conversations to have over a, you know, over a beer with your buddy sitting on the back porch, you're looking at the moon rise, you know?
0:10:26.630 --> 0:10:36.990
Hawthorne, Matthew
But they're not necessarily good conversations to have in a classroom setting, especially not a classroom setting where we've got three classes for this.
0:10:37.640 --> 0:10:40.610
Hawthorne, Matthew
Yeah, Sean, it gets into spiritual stuff pretty quickly.
0:10:40.700 --> 0:10:44.790
Hawthorne, Matthew
It also gets into the stuff that's not really scientific.
0:10:45.490 --> 0:10:46.140
Hawthorne, Matthew
Umm.
0:10:46.510 --> 0:10:48.220
Hawthorne, Matthew
And none of this is science.
0:10:48.230 --> 0:10:49.540
Hawthorne, Matthew
This is philosophy, OK?
0:10:50.170 --> 0:10:58.700
Hawthorne, Matthew
Umm, but it gets into the sorts of things where you can't really talk about it in an objective sort of manner.
0:10:58.710 --> 0:11:8.730
Hawthorne, Matthew
You can try a lot of people really try, but it's really hard to have, you know, like objective, real-world discussions about metaethics.
0:11:8.740 --> 0:11:10.720
Hawthorne, Matthew
It's it's too big.
0:11:10.830 --> 0:11:12.520
Hawthorne, Matthew
It's too fundamental.
0:11:12.890 --> 0:11:16.820
Hawthorne, Matthew
There is a value in having those conversations, but not in this class.
0:11:19.530 --> 0:11:28.460
Hawthorne, Matthew
What we do talk about, though, a lot is going to be normative ethics and applied ethics, normative ethics, you know, like like the slide says.
0:11:28.850 --> 0:11:31.240
Hawthorne, Matthew
Are are your practical guides?
0:11:31.310 --> 0:11:39.480
Hawthorne, Matthew
These are the ethical systems that try to help people make ethical decisions in their actual lives.
0:11:40.390 --> 0:11:44.670
Hawthorne, Matthew
UM, these ones we talked about because there are a lot more grounded.
0:11:44.830 --> 0:11:55.150
Hawthorne, Matthew
You know you can look at A normative ethical system and you can give objective feedback about strengths and weaknesses and practicality and applicability.
0:11:56.770 --> 0:12:2.880
Hawthorne, Matthew
And and you can have those sorts of discussions and we will about the three systems that we dive into.
0:12:3.230 --> 0:12:26.460
Hawthorne, Matthew
The other one is applied ethics and applied ethics is probably the the most relevant ethics on a day to day basis because it's applied it's ethics normative, ethical theories taken and applied to a specific field, environmental ethics, legal ethics, medical ethics, or in you're all case the ACM Code of Ethics as applied to computer engineers and computer scientists.
0:12:27.270 --> 0:12:33.370
Hawthorne, Matthew
So again it's it's it's grounded, it's real world, it's applicable.
0:12:33.500 --> 0:12:41.910
Hawthorne, Matthew
You can have really good conversations about value and worth, and you know, is this a valuable system of ethics?
0:12:41.920 --> 0:12:44.750
Hawthorne, Matthew
Is it worth trying to implement or is it not worth the effort?
0:12:44.760 --> 0:12:46.670
Hawthorne, Matthew
Are there better alternatives out there?
0:12:46.740 --> 0:12:54.720
Hawthorne, Matthew
You try having those questions about meta ethics and people start throwing fists, which is a thing I usually like to try and avoid my classes emphasis on usually.
0:12:56.830 --> 0:13:0.740
Hawthorne, Matthew
And so we really will be focusing on normative ethics and applied ethics.
0:13:1.50 --> 0:13:2.450
Hawthorne, Matthew
Not so much on metaethics.
0:13:2.880 --> 0:13:13.610
Hawthorne, Matthew
Umm my goal from these three classes that we have is I just want you all to be able to work ethical analysis into your classroom discussions.
0:13:13.620 --> 0:13:27.530
Hawthorne, Matthew
You know, I want the ethics test to show that you have all really thought about it and you know on a high falutin goal, I would like for you all to have the resources to maybe dive into ethics.
0:13:27.770 --> 0:13:32.980
Hawthorne, Matthew
You know, post this class in your in your lives if you haven't already.
0:13:33.400 --> 0:13:38.500
Hawthorne, Matthew
Quick question, how many of you have studied ethics in the past of any sort?
0:13:43.340 --> 0:13:45.340
Hawthorne, Matthew
OK, we've got a handful of people.
0:13:46.810 --> 0:13:53.200
Hawthorne, Matthew
Umm philosophy class Phillip my undergrad was in philosophy that absolutely counts.
0:13:54.800 --> 0:13:56.270
Hawthorne, Matthew
That's the best sort of ethics.
0:13:56.280 --> 0:13:56.660
Hawthorne, Matthew
Dang it.
0:13:58.750 --> 0:14:0.30
Hawthorne, Matthew
Yeah, I mean that.
0:14:0.40 --> 0:14:4.520
Hawthorne, Matthew
And Alex, you've had conversations on it, but nothing real formal.
0:14:4.650 --> 0:14:5.280
Hawthorne, Matthew
That's fine.
0:14:5.990 --> 0:14:12.300
Hawthorne, Matthew
One of the points that I like to make is that most ethical education in the modern world is not formal.
0:14:13.290 --> 0:14:14.900
Hawthorne, Matthew
Most of it is.
0:14:15.30 --> 0:14:19.200
Hawthorne, Matthew
You get it from just the world.
0:14:20.10 --> 0:14:22.20
Hawthorne, Matthew
This is especially the case with virtue ethics.
0:14:22.30 --> 0:14:29.520
Hawthorne, Matthew
When we talk about it, Jacob not really, no common in absolutely honest answer, Nicholas, you actually read nicomachean ethics.
0:14:29.530 --> 0:14:31.720
Hawthorne, Matthew
I have too, but did you do it as part of a class?
0:14:31.730 --> 0:14:32.930
Hawthorne, Matthew
Was it just for songs?
0:14:36.90 --> 0:14:37.320
Hawthorne, Matthew
Really interested in your answer here.
0:14:37.330 --> 0:14:37.790
Hawthorne, Matthew
So I want to know.
0:14:43.370 --> 0:14:43.860
Hawthorne, Matthew
I love it.
0:14:45.70 --> 0:14:48.370
Hawthorne, Matthew
Ohm saying you didn't have a specifics ethics class?
0:14:48.380 --> 0:14:48.580
Hawthorne, Matthew
Yeah.
0:14:48.590 --> 0:15:7.410
Hawthorne, Matthew
I mean it's, you know, pre modern era ethics like formalized ethical education was a was a foundational part of a, A, an adult education like people who got educated would have formal education in ethics.
0:15:7.940 --> 0:15:10.410
Hawthorne, Matthew
Umm, it's really it's.
0:15:10.520 --> 0:15:17.550
Hawthorne, Matthew
We live in a hyper specialized society these days, so a lot of people they don't really ever get even in higher education.
0:15:17.660 --> 0:15:20.770
Hawthorne, Matthew
They don't ever really get this sort of like formal education.
0:15:21.380 --> 0:15:22.530
Hawthorne, Matthew
They hear about it.
0:15:22.720 --> 0:15:28.190
Hawthorne, Matthew
Maybe they read about it, maybe they get it through alternative methods, but they don't study ethics.
0:15:28.200 --> 0:15:30.450
Hawthorne, Matthew
And I again bias here.
0:15:30.560 --> 0:15:32.590
Hawthorne, Matthew
Philosophy did a lot of ethics.
0:15:33.180 --> 0:15:38.770
Hawthorne, Matthew
My my my senior thesis was on the ethics of capitalism.
0:15:41.320 --> 0:15:44.680
Hawthorne, Matthew
OK, leadership training is where a lot of people get ethics these days.
0:15:46.920 --> 0:15:52.510
Hawthorne, Matthew
It's the major cases major places where people get ethical training will be either on the job.
0:15:53.430 --> 0:16:3.40
Hawthorne, Matthew
Umm well, they're get ethical training in applied ethics as applied to their job in some sort of leadership training or through whatever their religion is.
0:16:3.270 --> 0:16:6.720
Hawthorne, Matthew
Those are the major ways people get ethical educations in the modern world.
0:16:7.620 --> 0:16:8.200
Hawthorne, Matthew
Ohm.
0:16:9.180 --> 0:16:12.730
Hawthorne, Matthew
Anyway, can we please discuss the ethics of capitalism?
0:16:12.900 --> 0:16:15.0
Hawthorne, Matthew
I'm happy to have a side conversation about that.
0:16:18.80 --> 0:16:18.350
Hawthorne, Matthew
Uh.
0:16:20.640 --> 0:16:28.320
Hawthorne, Matthew
Modern capitalism does not ethically bear much of resemblance to capitalism as envisioned by Adam Smith when he wrote the wealth of nations.
0:16:30.0 --> 0:16:36.100
Hawthorne, Matthew
I'm just gonna leave it at that for now, but this is a this is an area that I'm very happy to talk about, you know, on the side.
0:16:37.730 --> 0:16:39.160
Hawthorne, Matthew
So anyway, so that's my goal.
0:16:39.170 --> 0:16:41.450
Hawthorne, Matthew
I want you all to form a habit of thinking ethically.
0:16:43.30 --> 0:16:46.480
Hawthorne, Matthew
So going back to the original question, what is an ethics here?
0:16:46.550 --> 0:16:52.960
Hawthorne, Matthew
Something I always want to emphasize is just because something is ethical doesn't mean it's legal and vice versa.
0:16:53.190 --> 0:16:55.940
Hawthorne, Matthew
Something can be perfectly legal and absolutely unethical.
0:16:56.790 --> 0:16:58.870
Hawthorne, Matthew
In fact, it's not even all that uncommon.
0:16:59.570 --> 0:17:3.320
Hawthorne, Matthew
Umm, you know, that's that's a thing, folks.
0:17:4.810 --> 0:17:11.340
Hawthorne, Matthew
In fact, you can even make an argument that certain elements of the legal code are on their face.
0:17:11.410 --> 0:17:12.520
Hawthorne, Matthew
Kind of unethical.
0:17:13.470 --> 0:17:17.180
Hawthorne, Matthew
You see, this oftentimes made in the tax code one way or the other.
0:17:17.830 --> 0:17:21.630
Hawthorne, Matthew
Both sides of the aisle are have been known to make that exact same argument.
0:17:22.350 --> 0:17:27.890
Hawthorne, Matthew
Umm, but it is important to remember that just because something is legal doesn't mean it's ethical.
0:17:28.30 --> 0:17:29.980
Hawthorne, Matthew
Slavery was legal.
0:17:31.40 --> 0:17:33.390
Hawthorne, Matthew
It was never ethical and I stand by that.
0:17:34.260 --> 0:17:39.120
Hawthorne, Matthew
You know, civil disobedience was illegal, but it was very ethical.
0:17:40.20 --> 0:17:43.510
Hawthorne, Matthew
You know you cannot equate ethics and legality.
0:17:43.960 --> 0:17:48.770
Hawthorne, Matthew
They are oftentimes related, but they are not the same thing and you always have to remember that.
0:17:49.880 --> 0:17:54.340
Hawthorne, Matthew
Umm, I also want us again to be careful about not confusing ethics with morality.
0:17:54.350 --> 0:17:59.910
Hawthorne, Matthew
You know you you can very ethically make very bad choices, right?
0:17:59.920 --> 0:18:11.570
Hawthorne, Matthew
You can very ethically make the very wrong choice and one of the ethical systems we'll talk about is one of the things you have to watch out for is that exact scenario, consequentialist ethics.
0:18:11.620 --> 0:18:14.210
Hawthorne, Matthew
It is very easy to make a decision.
0:18:14.360 --> 0:18:22.870
Hawthorne, Matthew
I wouldn't say very easy, but it's very possible to make a decision that is perfectly ethical under consequential is ethics and is an absolutely horrendous decision.
0:18:23.510 --> 0:18:25.380
Hawthorne, Matthew
It's a it's a common science fiction trope.
0:18:27.310 --> 0:18:32.420
Hawthorne, Matthew
So you got we do try to remember that just because something is ethical doesn't necessarily mean it's moral.
0:18:32.830 --> 0:18:41.640
Hawthorne, Matthew
Remember, ethics for us is the study of making decisions that are, you know, right and wrong decisions.
0:18:42.100 --> 0:18:47.290
Hawthorne, Matthew
And you can make a right decision under a code of ethics, and it'd be a very, very bad decision.
0:18:50.90 --> 0:18:52.0
Hawthorne, Matthew
So what are the three major frameworks of ethics?
0:18:52.10 --> 0:18:56.720
Hawthorne, Matthew
So I've already referred to two of them, but the first one we're gonna talk about is virtue ethics.
0:18:56.790 --> 0:19:5.160
Hawthorne, Matthew
When we talk about virtue ethics in the next class, we're going to take a deeper look at Nicomachean ethics, Aristotle's systems of ethics.
0:19:5.290 --> 0:19:10.910
Hawthorne, Matthew
Mostly because even though Aristotle was a, he was not the best of people.
0:19:11.640 --> 0:19:14.110
Hawthorne, Matthew
He was a racist, classist, sexist.
0:19:16.590 --> 0:19:22.360
Hawthorne, Matthew
There was at least another one, but the dude literally did not think that poor people could be fully ethic.
0:19:22.370 --> 0:19:24.360
Hawthorne, Matthew
He did not think that women could be fully ethical.
0:19:24.430 --> 0:19:35.250
Hawthorne, Matthew
He did not think that anyone who was non Greek could be fully ethical, but that's a product of his time and you have to remember that we have to view it through that the system of ethics that he made.
0:19:36.210 --> 0:19:44.390
Hawthorne, Matthew
It was pretty amazing and it's because he took a really systemic view of what constitutes ethics.
0:19:44.820 --> 0:19:46.400
Hawthorne, Matthew
So we're gonna use him as the example.
0:19:47.320 --> 0:20:1.120
Hawthorne, Matthew
Umm, but virtue ethics and emphasizes adopting an ethical character as as proposed by the virtue ethicist which already tells you that this one tends to be very.
0:20:3.180 --> 0:20:21.690
Hawthorne, Matthew
Very subjective and you gotta be careful about that because you know what was ethical for a Roman citizen, you know, during the time of the Stoics may not necessarily be what is ethical for, you know, a desk jockey in Louisville, KY in 2024.
0:20:21.700 --> 0:20:25.540
Hawthorne, Matthew
24 and that's OK, right?
0:20:25.610 --> 0:20:27.80
Hawthorne, Matthew
Because you gotta.
0:20:27.90 --> 0:20:28.400
Hawthorne, Matthew
You gotta look at it.
0:20:28.510 --> 0:20:33.820
Hawthorne, Matthew
You can look at the past through the lens of the present, and that's a valuable and good thing to do.
0:20:34.90 --> 0:20:39.620
Hawthorne, Matthew
But you also have to look at the paths through the lens of the past and through what is there umm?
0:20:40.200 --> 0:20:43.990
Hawthorne, Matthew
That being said, virtue ethics is one of the oldest ethical theories.
0:20:44.980 --> 0:20:56.990
Hawthorne, Matthew
You know, classical Greek and Roman ethics is almost all virtual ethics, so it scism Epicureanism, Aristotles, nicomachean ethics, Plato's ethics, where virtue ethics.
0:20:57.620 --> 0:21:0.340
Hawthorne, Matthew
You also see it in a lot of the early Christian philosophers.
0:21:0.350 --> 0:21:9.240
Hawthorne, Matthew
Aquinas was basically rewrote nicomachean ethics and it's something theological Augustin was very platonic and his approach to ethics.
0:21:10.240 --> 0:21:12.170
Hawthorne, Matthew
Umm, you also see it?
0:21:12.180 --> 0:21:13.430
Hawthorne, Matthew
It's very widespread.
0:21:13.660 --> 0:21:16.150
Hawthorne, Matthew
Confucian ethics is very virtue ethics oriented.
0:21:16.260 --> 0:21:27.730
Hawthorne, Matthew
Daoist ethics very virtue ethics oriented, you know, it's how well do you embody the Dow, but there are also like specific virtues that are espoused in the dowdy Cheng and in the etching.
0:21:28.260 --> 0:21:32.130
Hawthorne, Matthew
Humility, flexibility, perseverance is a big one.
0:21:33.510 --> 0:21:37.620
Hawthorne, Matthew
Buddhist ethics is absolutely a virtue ethics system.
0:21:38.570 --> 0:21:41.700
Hawthorne, Matthew
You know you've got the the eight fold path and the five precepts.
0:21:43.180 --> 0:21:59.610
Hawthorne, Matthew
You know, a lot of world real world ethical theory is at it Hindu ethics, which I haven't read as much of, but in the Upanishads the ethics ethical theory espoused there is very much a virtue ethics theory.
0:22:1.420 --> 0:22:10.60
Hawthorne, Matthew
Really looking at the the foundational ethics, it's virtue ethics, and it's super widespread. Hi.
0:22:10.130 --> 0:22:10.720
Hawthorne, Matthew
So I'm gonna.
0:22:10.790 --> 0:22:15.240
Hawthorne, Matthew
I'm gonna lay some virtues on you, and I want to see if you all can identify them.
0:22:16.550 --> 0:22:17.350
Hawthorne, Matthew
Hold on a second.
0:22:17.390 --> 0:22:19.640
Hawthorne, Matthew
I always have to look this up to make certain I've got it right.
0:22:25.710 --> 0:22:26.960
Hawthorne, Matthew
So I want to start off with first.
0:22:26.970 --> 0:22:35.160
Hawthorne, Matthew
Does anyone recognize the trifecta of ethics that goes by courage, wisdom, and power?
0:22:46.380 --> 0:22:47.730
Hawthorne, Matthew
Yeah, that's the Triforce.
0:22:51.460 --> 0:22:52.70
Hawthorne, Matthew
Umm.
0:22:54.100 --> 0:22:55.290
Hawthorne, Matthew
What about?
0:22:55.680 --> 0:22:59.140
Hawthorne, Matthew
What about courage, ambition, loyalty and intelligence?
0:23:3.490 --> 0:23:8.20
Hawthorne, Matthew
And recognize that Harry Potter, Harry Potter added.
0:23:8.30 --> 0:23:9.550
Hawthorne, Matthew
Its core is a virtue play.
0:23:11.490 --> 0:23:15.180
Hawthorne, Matthew
Quite apart from everything that was done wrong in that, at its core, it's a virtue play.
0:23:15.290 --> 0:23:17.120
Hawthorne, Matthew
I really don't like what she did with Slytherins.
0:23:17.190 --> 0:23:18.960
Hawthorne, Matthew
Ambition is not, in and of itself, bad.
0:23:18.970 --> 0:23:21.820
Hawthorne, Matthew
I don't think, but that's looking into metaethics here.
0:23:21.830 --> 0:23:23.580
Hawthorne, Matthew
Here's one that I always like bringing up.
0:23:26.140 --> 0:23:31.330
Hawthorne, Matthew
Honesty, kindness, laughter, generosity, loyalty, and friendship.
0:23:31.400 --> 0:23:32.800
Hawthorne, Matthew
Does anyone recognize those?
0:23:45.580 --> 0:23:46.690
Hawthorne, Matthew
Very close, Austin.
0:23:46.700 --> 0:23:47.350
Hawthorne, Matthew
Not quite though.
0:23:49.240 --> 0:23:50.650
Hawthorne, Matthew
Yeah, and it is absolutely.
0:23:50.660 --> 0:23:51.360
Hawthorne, Matthew
My little ponies.
0:23:52.360 --> 0:23:56.120
Hawthorne, Matthew
Yep, I for my daughter's birthday, she does.
0:23:56.130 --> 0:24:3.700
Hawthorne, Matthew
Turned 12 and for her birthday we sat down and marathoned my little ponies cause I watched so much my little ponies when she was younger.
0:24:4.590 --> 0:24:12.610
Hawthorne, Matthew
And I gotta tell you folks, like, unironically, some of the best kids entertainment out there, but it's all about virtue ethics, right?
0:24:12.680 --> 0:24:14.810
Hawthorne, Matthew
All of the ponies represent a little virtue.
0:24:14.890 --> 0:24:17.130
Hawthorne, Matthew
And then when you put them all together, it makes magic.
0:24:19.240 --> 0:24:26.390
Hawthorne, Matthew
Which sounds really silly, but that's how a lot of the virtue ethics education in the world happens.
0:24:26.520 --> 0:24:39.670
Hawthorne, Matthew
You pick it up through that sort of mass media, which is part of why looking at virtue ethics is so important, because you need to know what you're being taught.
0:24:40.520 --> 0:24:49.340
Hawthorne, Matthew
You always want to look at, you know, if you're trying to think ethically, you always want to look at what are.
0:24:49.450 --> 0:24:51.60
Hawthorne, Matthew
What is this media?
0:24:51.510 --> 0:24:52.900
Hawthorne, Matthew
What is this embodying?
0:24:53.110 --> 0:25:5.500
Hawthorne, Matthew
You know what virtues are we seeing espoused by this media as something that is worth, umm, worth at worth advocating worth embodying, right?
0:25:5.620 --> 0:25:9.540
Hawthorne, Matthew
It's part of why my favorite Avenger is and always will be Captain America.
0:25:10.490 --> 0:25:19.290
Hawthorne, Matthew
You know the dude was a virtue ethics paragon paragon in this setting, and he was opposed.
0:25:19.500 --> 0:25:25.580
Hawthorne, Matthew
But friends with Tony Stark, who was very much a consequentialist ethics so cool when you start thinking about it?
0:25:27.150 --> 0:25:31.100
Hawthorne, Matthew
Umm, there is some modern traction with virtue ethics.
0:25:31.110 --> 0:25:33.200
Hawthorne, Matthew
I don't want you to think it's just all old.
0:25:33.510 --> 0:25:35.960
Hawthorne, Matthew
Alistair McIntyre has done a lot of writing about it.
0:25:36.90 --> 0:25:43.380
Hawthorne, Matthew
The ethics of care is one of the ethical systems that I have a lot of respect for, and it's virtue ethics and core.
0:25:44.230 --> 0:25:47.520
Hawthorne, Matthew
But end of the day, virtue ethics is the old one.
0:25:47.570 --> 0:25:51.120
Hawthorne, Matthew
It's the widespread one, and it's the one that is most common.
0:25:51.250 --> 0:25:54.530
Hawthorne, Matthew
I feel in the day to day world.
0:25:55.670 --> 0:25:58.160
Hawthorne, Matthew
Next one, we're going to talk about is deontological ethics.
0:25:58.170 --> 0:26:2.690
Hawthorne, Matthew
And when we talk about this in more detail, we're gonna look at Emmanuel counts.
0:26:2.890 --> 0:26:16.780
Hawthorne, Matthew
Umm, his categorical imperatives and what count does is he tried to create some deontological guidelines, rules that were applicable across the whole of human spectrum.
0:26:16.890 --> 0:26:17.840
Hawthorne, Matthew
He didn't succeed.
0:26:18.270 --> 0:26:23.770
Hawthorne, Matthew
You have to admire his effort, but if any of you have ever read CONT, I feel your pain.
0:26:24.580 --> 0:26:25.210
Hawthorne, Matthew
Umm.
0:26:25.680 --> 0:26:30.650
Hawthorne, Matthew
That being said, what deontological ethics is is it's duty or rule based ethical theories.
0:26:31.580 --> 0:26:37.30
Hawthorne, Matthew
It tries to propose certain rules and as long as you follow those rules, you are acting ethically.
0:26:37.340 --> 0:26:42.670
Hawthorne, Matthew
It also includes write space theories where write space theories are the opposite side of the coin.
0:26:43.610 --> 0:26:52.700
Hawthorne, Matthew
You know, rights based theories are as long as you are acting within these rights and not pass them, you are acting ethically.
0:26:53.230 --> 0:26:58.150
Hawthorne, Matthew
So it's it's a little more open ended, but it's the same basic concept.
0:26:58.160 --> 0:27:2.190
Hawthorne, Matthew
You have certain parameters around your behavior that are.
0:27:2.200 --> 0:27:3.80
Hawthorne, Matthew
You are supposed to follow.
0:27:5.880 --> 0:27:17.130
Hawthorne, Matthew
Duty based rules based deontological ethics tend to be more common, and you see this most often in both the Legal code reference earlier, though, just because it's legal doesn't mean it's ethical.
0:27:17.320 --> 0:27:24.890
Hawthorne, Matthew
But the legal code in a way really is like an attempt to set, you know, certain fundamental groundwork.
0:27:24.900 --> 0:27:27.530
Hawthorne, Matthew
Deontological rules of behavior for society.
0:27:27.860 --> 0:27:32.390
Hawthorne, Matthew
But you also see it in most professional ethics are deontological in nature.
0:27:33.200 --> 0:27:42.180
Hawthorne, Matthew
The American Bar Association Code of Legal Ethics is a book unto itself, and in order to be a lawyer, you have to pass a bar exam that's focused on ethics.
0:27:42.310 --> 0:27:45.750
Hawthorne, Matthew
Or at least you did 20 some years ago when I became a lawyer.
0:27:47.560 --> 0:27:53.430
Hawthorne, Matthew
So you know, the American Medical Association has a deontological code of ethics.
0:27:54.160 --> 0:28:0.310
Hawthorne, Matthew
The ACM Code of Ethics at its core, even though one of the things I like about is, it wraps in all three.
0:28:0.580 --> 0:28:17.100
Hawthorne, Matthew
At its core is a deontological code of ethics, the IEEE Code of Ethics is very clearly deontological, so you see a lot of the deontological framework of ethics in just the everyday real world, and it's got some advantages, right?
0:28:17.450 --> 0:28:22.630
Hawthorne, Matthew
It's clear it makes sense if you're following the rules, you are acting ethically.
0:28:24.200 --> 0:28:30.40
Hawthorne, Matthew
There's a certain sort of, you know, there's a certain virtue in that.
0:28:30.170 --> 0:28:30.730
Hawthorne, Matthew
Umm.
0:28:31.190 --> 0:28:32.660
Hawthorne, Matthew
And also has some weaknesses.
0:28:32.750 --> 0:28:36.0
Hawthorne, Matthew
And again, we'll talk about all of this, Richard.
0:28:36.10 --> 0:28:39.260
Hawthorne, Matthew
Yes, the Bill of Rights is a deontological ethical code.
0:28:39.710 --> 0:28:41.730
Hawthorne, Matthew
Now it's rights based, not duty based.
0:28:43.720 --> 0:28:47.830
Hawthorne, Matthew
It there's certain allusions to duty within it, but that's part of the problem with.
0:28:47.920 --> 0:28:50.230
Hawthorne, Matthew
I mean, laws are written by people.
0:28:53.140 --> 0:29:0.330
Hawthorne, Matthew
But yeah, it is a right based deontological ethical code that is meant to apply as a fundamental basis for American Society.
0:29:0.340 --> 0:29:2.790
Hawthorne, Matthew
It's a societal level ethical code?
0:29:3.0 --> 0:29:3.750
Hawthorne, Matthew
Adam asked.
0:29:3.760 --> 0:29:6.310
Hawthorne, Matthew
Is Deon deontological ethics.
0:29:6.320 --> 0:29:7.330
Hawthorne, Matthew
I hate that word.
0:29:8.80 --> 0:29:12.530
Hawthorne, Matthew
Is it more prevalent where people act ethical because they are concerned about the consequences of not acting ethically?
0:29:12.590 --> 0:29:12.780
Hawthorne, Matthew
Really.
0:29:13.190 --> 0:29:18.40
Hawthorne, Matthew
I'm I don't know if it's more prevalent than in virtue ethics.
0:29:18.50 --> 0:29:20.480
Hawthorne, Matthew
It's just the consequences tend to be more clear.
0:29:21.150 --> 0:29:22.140
Hawthorne, Matthew
Virtue ethics.
0:29:22.150 --> 0:29:30.50
Hawthorne, Matthew
The consequences of not acting ethically either are more self focused and we'll definitely talk about this when we talk about Mickey and ethics.
0:29:30.310 --> 0:29:35.920
Hawthorne, Matthew
Umm, you know the the one of the cool things about that Aristotle did there is he started by the end.
0:29:36.10 --> 0:29:37.270
Hawthorne, Matthew
What is the goal of ethics?
0:29:37.280 --> 0:29:38.220
Hawthorne, Matthew
And it's to live.
0:29:38.270 --> 0:29:44.490
Hawthorne, Matthew
It's to achieve you demonia which is, you know, vaguely translated as happiness.
0:29:44.680 --> 0:29:47.680
Hawthorne, Matthew
But it's more like happiness with yourself, right?
0:29:47.740 --> 0:29:51.780
Hawthorne, Matthew
It's basically the ability to look back on your life and be like alright.
0:29:52.160 --> 0:29:52.780
Hawthorne, Matthew
Yeah, I did that.
0:29:53.540 --> 0:29:53.990
Hawthorne, Matthew
Good.
0:29:54.500 --> 0:29:55.70
Hawthorne, Matthew
Umm.
0:29:55.440 --> 0:29:57.610
Hawthorne, Matthew
And less like joy, OK.
0:29:58.900 --> 0:30:8.240
Hawthorne, Matthew
But the the goal there was by living in a virtuous life, you avoided, you know, feelings of shame, feelings of guilt.
0:30:8.250 --> 0:30:16.780
Hawthorne, Matthew
You especially avoided external shame because a lot of the virtue ethics, a lot of we're virtue ethics arose.
0:30:16.820 --> 0:30:33.220
Hawthorne, Matthew
Shame was a very it was a used tool to enforce social compliance, so by acting in ways where you couldn't be shamed, or if you were shamed, you were confident that you did the right thing anyways.
0:30:33.370 --> 0:30:34.820
Hawthorne, Matthew
Was super important to people.
0:30:35.90 --> 0:30:38.610
Hawthorne, Matthew
That's super prevalent in Stoic philosophy.
0:30:38.650 --> 0:30:40.440
Hawthorne, Matthew
You know the stoic, stoic philosophy.
0:30:40.450 --> 0:30:50.540
Hawthorne, Matthew
Virtue ethics could basically be summed up as being able to be being able to act acting in such a way that you don't feel shame about yourself.
0:30:51.350 --> 0:31:5.210
Hawthorne, Matthew
Umm and deontological ethics, though it tends to be more clear what the consequence is if you, you know, if you, if you're a lawyer, and you don't act in accordance with the ABA Code of Ethics, you can lose your license.
0:31:5.730 --> 0:31:6.360
Hawthorne, Matthew
Same with this.
0:31:6.370 --> 0:31:10.580
Hawthorne, Matthew
If you're a doctor and you don't act in accordance with the medical code of Ethics, you can use lose your license.
0:31:11.580 --> 0:31:18.540
Hawthorne, Matthew
You know, and they or you could have some sort of disciplinary action, you know, things like that.
0:31:19.150 --> 0:31:31.340
Hawthorne, Matthew
So I would say Adam, yes, it is and this long winded answer, I'm sorry it is more prevalent where people act ethical because they're concerned about the consequences, but the difference is deontological.
0:31:31.350 --> 0:31:32.90
Hawthorne, Matthew
Ethics doesn't care.
0:31:33.180 --> 0:31:35.530
Hawthorne, Matthew
Virtue ethics cares about why you're acting ethically.
0:31:36.180 --> 0:31:39.550
Hawthorne, Matthew
Deontological ethics doesn't care as long as you're acting ethically.
0:31:40.60 --> 0:31:44.440
Hawthorne, Matthew
Good on you if you're only doing it because you don't want consequences.
0:31:44.570 --> 0:31:45.20
Hawthorne, Matthew
Don't care.
0:31:45.30 --> 0:31:47.440
Hawthorne, Matthew
You're still acting ethically, you know.
0:31:47.530 --> 0:31:49.760
Hawthorne, Matthew
So in that way, it's a more objective sense.
0:31:49.770 --> 0:31:57.140
Hawthorne, Matthew
It doesn't really matter why you're doing, why you're acting ethically as much as you are following the rules and acting ethically.
0:32:2.250 --> 0:32:2.590
Hawthorne, Matthew
Umm.
0:32:2.970 --> 0:32:6.890
Hawthorne, Matthew
And then the third system that we talked about is consequentialism. Umm.
0:32:8.970 --> 0:32:16.300
Hawthorne, Matthew
To uh quote Samuel Jackson, some person is always gonna go on about ends.
0:32:16.310 --> 0:32:16.900
Hawthorne, Matthew
Justify the means.
0:32:18.440 --> 0:32:20.160
Hawthorne, Matthew
Censored for year olds, delicate hearing.
0:32:22.230 --> 0:32:25.140
Hawthorne, Matthew
But realistically, that's not quite what it means.
0:32:25.150 --> 0:32:30.500
Hawthorne, Matthew
That tends to be a popular conception of consequentialist ethics, but that's not quite what it means.
0:32:30.710 --> 0:32:44.380
Hawthorne, Matthew
OK, consequentialist ethics at its core is simply you act with an eye towards the consequences of your actions, with an eye towards maximizing benefit and minimizing harm.
0:32:44.490 --> 0:32:47.940
Hawthorne, Matthew
There are a bunch of different categories of consequentialist ethics.
0:32:48.90 --> 0:32:53.930
Hawthorne, Matthew
There's internally focused, there's externally focused, there's benefit focused, there's harm focused.
0:32:54.240 --> 0:32:57.470
Hawthorne, Matthew
Umm, but what?
0:32:57.480 --> 0:33:3.240
Hawthorne, Matthew
We'll talk about next time we meet is the utilitarianism or the utilitarianists.
0:33:4.930 --> 0:33:8.220
Hawthorne, Matthew
Formulation of consequence ethics we'll mostly use mills formulation.
0:33:9.230 --> 0:33:13.750
Hawthorne, Matthew
I tend to mix together, bent them and mill my philosophy.
0:33:13.760 --> 0:33:18.590
Hawthorne, Matthew
Professors in college would probably throws things at me for doing so, but this isn't a philosophy course.
0:33:18.600 --> 0:33:32.330
Hawthorne, Matthew
This is computer engineering course and for those ones, what you're really what you're really saying is you're trying to do the greatest amount of good for the most people with the least harm.
0:33:32.400 --> 0:33:44.920
Hawthorne, Matthew
So you're it's a multifaceted, almost algorithmic analysis where you're trying to maximize good both in amount and breath while minimizing harm.
0:33:47.400 --> 0:33:58.70
Hawthorne, Matthew
Now, some consequentialist theories will go so far as to say that the consequences of the action or decision really do determine whether it was ethical or not.
0:33:58.200 --> 0:33:59.630
Hawthorne, Matthew
Most of them don't.
0:34:0.20 --> 0:34:6.70
Hawthorne, Matthew
Most of them recognize that we are human actors with limited information and limited understanding.
0:34:6.240 --> 0:34:15.740
Hawthorne, Matthew
So the goal is to make the best decision that you can with the information that you have and with proper exercise of reasonable foresight for potential consequences.
0:34:17.820 --> 0:34:19.170
Hawthorne, Matthew
Because none of us are perfect.
0:34:19.620 --> 0:34:19.940
Hawthorne, Matthew
Right.
0:34:21.570 --> 0:34:26.600
Hawthorne, Matthew
I will say this is a major political ethical theory, at least in the US.
0:34:27.290 --> 0:34:29.990
Hawthorne, Matthew
If you're looking at a lot of the.
0:34:32.640 --> 0:34:33.190
Hawthorne, Matthew
It's it's.
0:34:33.240 --> 0:34:46.810
Hawthorne, Matthew
It gets harder to maintain this outlook sometimes, but if you're looking at a lot of the discourse, what it boils down to is a fundamental disagreement over what constitutes benefit and what constitutes harm.
0:34:47.20 --> 0:34:51.840
Hawthorne, Matthew
Now always like using this example, but how many of you consider taxes a harm?
0:34:54.890 --> 0:34:56.530
Hawthorne, Matthew
Some brave soul is going to raise their hand.
0:34:58.500 --> 0:34:58.700
Hawthorne, Matthew
Yeah.
0:35:1.320 --> 0:35:7.570
Hawthorne, Matthew
She, Sean takes the more balanced, you know, depends on what they are used for, and that's usually the follow up question, right.
0:35:8.40 --> 0:35:14.190
Hawthorne, Matthew
It's like, OK, so you you say taxes are harm, but are public fire departments are harm, you know?
0:35:14.200 --> 0:35:22.830
Hawthorne, Matthew
Is the Interstate Highway system of harm, you know, and you'll get some people, usually ******** libertarians, who are like, yeah, it's all terrible.
0:35:22.840 --> 0:35:24.690
Hawthorne, Matthew
Don't do it, and that's fine.
0:35:24.700 --> 0:35:25.940
Hawthorne, Matthew
That's a that is a.
0:35:26.80 --> 0:35:31.240
Hawthorne, Matthew
That is a position, but most people when you start drilling into it are gonna be like, well, no.
0:35:31.250 --> 0:35:42.570
Hawthorne, Matthew
OK, public education is a benefit, you know, but you're really what you're really getting into is what's you're not wrong, Jacob.
0:35:42.820 --> 0:35:45.810
Hawthorne, Matthew
But I would argue that it's not really, it doesn't.
0:35:46.630 --> 0:35:47.450
Hawthorne, Matthew
That's a different issue.
0:35:50.400 --> 0:35:54.830
Hawthorne, Matthew
Alex is correct, the necessary to maintain infrastructure, but they can be abused.
0:35:54.880 --> 0:35:55.450
Hawthorne, Matthew
But you're fine.
0:35:55.460 --> 0:35:55.950
Hawthorne, Matthew
That's that's.
0:35:55.960 --> 0:35:57.910
Hawthorne, Matthew
That's just the real world, right?
0:35:59.120 --> 0:36:1.790
Hawthorne, Matthew
I mean, end of the day, that's that's true about almost everything.
0:36:4.0 --> 0:36:6.930
Hawthorne, Matthew
But you still use it as a guiding principle, right?
0:36:7.180 --> 0:36:10.530
Hawthorne, Matthew
You want to taxes are a harm.
0:36:10.750 --> 0:36:15.850
Hawthorne, Matthew
OK, I'm gonna just come out, and I'm gonna say taxes are a harm, but they could be.
0:36:15.900 --> 0:36:26.630
Hawthorne, Matthew
When used properly, the minimum harm necessary to maximize benefit, for example public education, is a benefit to a society.
0:36:27.320 --> 0:36:43.720
Hawthorne, Matthew
You know, having a, having a populace that is educated to a certain fundamental level, which in the US we have decided as a high school education is a benefit to the society at a large and it's very often actually a benefit to every individual that interacts within that society.
0:36:44.490 --> 0:36:48.600
Hawthorne, Matthew
But how do you get public education without taxes, right?
0:36:48.720 --> 0:36:51.400
Hawthorne, Matthew
So taxes are a harm, but they are harmed.
0:36:51.410 --> 0:36:53.330
Hawthorne, Matthew
That is supposed to be minimized.
0:36:56.560 --> 0:37:1.250
Hawthorne, Matthew
While you maximize the benefit that comes from them unless necessary evil, right?
0:37:1.410 --> 0:37:4.60
Hawthorne, Matthew
Except for we don't like to use the term evil in here, Jay cause.
0:37:4.70 --> 0:37:5.60
Hawthorne, Matthew
But that's metaethics.
0:37:6.110 --> 0:37:6.440
Hawthorne, Matthew
Umm.
0:37:6.450 --> 0:37:12.370
Hawthorne, Matthew
Sean, a lot of people will, will, you know, especially like nuclear weapons.
0:37:12.380 --> 0:37:26.690
Hawthorne, Matthew
It's hard to justify those, even under consequentialist form of ethics, but you can right mutually assured destruction, at least for the first you know, for the last 50 years of the 20th century worked right?
0:37:26.740 --> 0:37:28.550
Hawthorne, Matthew
We didn't have a nuclear war.
0:37:28.820 --> 0:37:32.770
Hawthorne, Matthew
Exactly 2 nuclear weapons have ever been dropped as an act of war.
0:37:34.350 --> 0:37:40.80
Hawthorne, Matthew
So you can actually make an argument that mutually assured destruction was a successful use of consequentialist ethics.
0:37:42.590 --> 0:37:43.880
Hawthorne, Matthew
I'm not making that.
0:37:43.930 --> 0:37:46.380
Hawthorne, Matthew
I'm not a I'm not a modern historian.
0:37:46.490 --> 0:37:54.420
Hawthorne, Matthew
That's not my area of expertise, but I'm saying you can make that argument, and that's both the strength and the weakness of consequentialist ethics.
0:37:55.70 --> 0:37:58.440
Hawthorne, Matthew
Umm it it again?
0:37:58.450 --> 0:37:59.240
Hawthorne, Matthew
We're not perfect.
0:37:59.790 --> 0:38:5.350
Hawthorne, Matthew
You look at it in hindsight, the hindsight analysis doesn't help you when you have to make a decision, right?
0:38:6.220 --> 0:38:12.970
Hawthorne, Matthew
Any ethical theory that only works in hindsight is kind of pointless from a practical standpoint.
0:38:13.100 --> 0:38:19.750
Hawthorne, Matthew
Maybe as useful from a meta and that now metaethical analysis, but it's not useful to people just trying to live a good life.
0:38:19.940 --> 0:38:22.560
Hawthorne, Matthew
So you have to be looking forward. Umm.
0:38:23.40 --> 0:38:25.710
Hawthorne, Matthew
So yeah, major political theory.
0:38:26.340 --> 0:38:28.210
Hawthorne, Matthew
But there's a lot of issues with it.
0:38:28.710 --> 0:38:31.410
Hawthorne, Matthew
Fundamental issue is how do you define benefit?
0:38:31.420 --> 0:38:32.750
Hawthorne, Matthew
How do you define harm?
0:38:32.900 --> 0:38:40.570
Hawthorne, Matthew
How do you balance, you know, if something deals 100 units of benefit but deals 10 units of harm?
0:38:40.700 --> 0:38:46.450
Hawthorne, Matthew
Is that better than something that deals 50 units of benefit, but only 5 units of harm?
0:38:46.660 --> 0:38:47.750
Hawthorne, Matthew
Or are they equivalent?
0:38:48.240 --> 0:38:51.550
Hawthorne, Matthew
Mathematically, they're equivalent, but are they actually equivalent?
0:38:54.30 --> 0:38:57.270
Hawthorne, Matthew
Those are the sorts of things that get Dr Consequentialist at.
0:38:57.440 --> 0:39:0.250
Hawthorne, Matthew
Is mad, but that's why they do it.
0:39:1.160 --> 0:39:7.150
Hawthorne, Matthew
Umm, the other thing about consequentialist ethics is it does get some Flack for being basically ethical mathematics.
0:39:7.630 --> 0:39:9.980
Hawthorne, Matthew
And of course, that's not really the case.
0:39:9.990 --> 0:39:13.550
Hawthorne, Matthew
You can't quantify these sorts of things to that level of detail.
0:39:14.300 --> 0:39:19.590
Hawthorne, Matthew
Umm, but you can see why that that gets that particular criticism.
0:39:19.650 --> 0:39:21.230
Hawthorne, Matthew
Criticism gets made from time to time.
0:39:24.90 --> 0:39:25.190
Hawthorne, Matthew
Alright, moving on.
0:39:27.330 --> 0:39:31.730
Hawthorne, Matthew
And then applied ethics like I mentioned earlier, we're going to use the ACM Code of Ethics.
0:39:31.840 --> 0:39:37.490
Hawthorne, Matthew
We're using it specifically because the ACM Code of Ethics kind of wraps together all three of these, and I really like that.
0:39:37.860 --> 0:39:45.330
Hawthorne, Matthew
One of the things I want you to take away from this class is basically nobody uses a single system of ethics in their day-to-day life.
0:39:45.440 --> 0:39:50.440
Hawthorne, Matthew
Most everybody is using some mishmash amalgamation.
0:39:50.510 --> 0:39:52.590
Hawthorne, Matthew
Uh, half a dozen different systems of ethics.
0:39:53.540 --> 0:39:58.650
Hawthorne, Matthew
You know, maybe one of the guiding guiding principles of your life is what would Aragorn do?
0:39:59.80 --> 0:40:3.100
Hawthorne, Matthew
In which case good on you, it's hard to find a better, better example.
0:40:3.800 --> 0:40:4.360
Hawthorne, Matthew
Umm.
0:40:4.620 --> 0:40:6.460
Hawthorne, Matthew
Maybe what would Sam do right?
0:40:6.690 --> 0:40:18.30
Hawthorne, Matthew
Umm, but you've got most people you know they're using some combination of virtue ethics, deontological ethics, consequentialist ethics, and they're using it.
0:40:18.40 --> 0:40:20.750
Hawthorne, Matthew
And they're doing all of this analysis completely subconsciously.
0:40:21.390 --> 0:40:22.590
Hawthorne, Matthew
OK, that's cool.
0:40:23.660 --> 0:40:24.980
Hawthorne, Matthew
That's how most people work.
0:40:26.660 --> 0:40:36.940
Hawthorne, Matthew
I would like for you all to look at that to examine that, to look at how you make ethical decisions and try to explicate, you know, where does this come from?
0:40:37.180 --> 0:40:38.380
Hawthorne, Matthew
Where does this come from?
0:40:38.630 --> 0:40:39.610
Hawthorne, Matthew
Why is this?
0:40:39.620 --> 0:40:47.60
Hawthorne, Matthew
One of the things I think about when I have to decide how to act, I use Lord of the Rings because I was practically raised on Lord of the Rings.
0:40:47.330 --> 0:40:47.800
Hawthorne, Matthew
Right.
0:40:48.130 --> 0:40:49.720
Hawthorne, Matthew
Like I read that book so many times.
0:40:50.30 --> 0:40:50.960
Hawthorne, Matthew
Absolutely loved it.
0:40:51.60 --> 0:40:54.490
Hawthorne, Matthew
The movies charge of the Rohirrim every time tears.
0:40:56.560 --> 0:41:1.580
Hawthorne, Matthew
You know, for me, that was foundational, right?
0:41:2.360 --> 0:41:14.30
Hawthorne, Matthew
Same with like the tales of King Arthur and Robin Hood, like I was raised on classical I classical, but on medieval, you know, mythology and fantasy basically.
0:41:14.260 --> 0:41:16.70
Hawthorne, Matthew
And that's had a profound impact on me.
0:41:16.200 --> 0:41:26.80
Hawthorne, Matthew
Likewise, my ******** evangelical Christian upbringing has had a deep impact on me, as have my later studies in Buddhist and Daoist Buddhism and Daoism.
0:41:27.190 --> 0:41:30.640
Hawthorne, Matthew
You know all of these things have had an impact.
0:41:30.650 --> 0:41:33.280
Hawthorne, Matthew
My military upbringing has had an impact on me.
0:41:35.250 --> 0:41:42.320
Hawthorne, Matthew
You know, the fact that I've worked for nonprofits mostly in the medical field for my entire career has had an impact on me.
0:41:42.390 --> 0:41:48.0
Hawthorne, Matthew
All of these things have had an impact on me and have helped inform how I try to make ethical decisions.
0:41:48.210 --> 0:42:3.600
Hawthorne, Matthew
Even when I fail and that's one of the things that is really makes the study of ethics worth it, is looking at, you know, really digging into why you make the decisions you make both both when you fail but also when you succeed.
0:42:3.610 --> 0:42:5.240
Hawthorne, Matthew
Like, hey, I made a really good decision.
0:42:5.330 --> 0:42:5.800
Hawthorne, Matthew
Why?
0:42:6.310 --> 0:42:12.800
Hawthorne, Matthew
What made me make that decision and you know, to pull a phrase from Socrates, the unexamined life is not worth living, right?
0:42:12.890 --> 0:42:13.940
Hawthorne, Matthew
Examine your life.
0:42:13.990 --> 0:42:16.300
Hawthorne, Matthew
Figure things out? Umm.
0:42:18.340 --> 0:42:29.570
Hawthorne, Matthew
One of the other reasons why I like looking at this is you will run into a time in your in your lives where there will be a conflict between your personal ethics, your professional ethics, and your societal ethics.
0:42:30.310 --> 0:42:32.320
Hawthorne, Matthew
Umm, it happens to everybody.
0:42:32.730 --> 0:42:35.610
Hawthorne, Matthew
Could be minor, could be a very little thing, right?
0:42:37.180 --> 0:42:44.830
Hawthorne, Matthew
But you are going to run into a situation where there is a conflict, you know, could be you have to fire somebody that you really don't think should be fired.
0:42:45.100 --> 0:42:49.50
Hawthorne, Matthew
But the bottom line demands that you let people go.
0:42:49.500 --> 0:42:51.150
Hawthorne, Matthew
OK, I'm a manager.
0:42:51.160 --> 0:42:52.880
Hawthorne, Matthew
That's something that I have to deal with.
0:42:53.580 --> 0:42:56.370
Hawthorne, Matthew
Umm, you know, how do you handle that?
0:42:56.460 --> 0:43:3.300
Hawthorne, Matthew
What do you do when personal ethics and professional ethics aren't necessarily in line with each other?
0:43:3.840 --> 0:43:4.260
Hawthorne, Matthew
Umm.
0:43:4.660 --> 0:43:10.750
Hawthorne, Matthew
And in order to avoid some really painful cognitive dissonance, it really helps to try and examine this before it happens to you.
0:43:11.860 --> 0:43:18.160
Hawthorne, Matthew
Umm, so the last bit before we just open it up for questions and discussions is your reading assignment.
0:43:20.70 --> 0:43:26.500
Hawthorne, Matthew
As I say in the slide, I don't actually expect you all to read those other than the person who already read neck McCain ethics.
0:43:26.510 --> 0:43:31.980
Hawthorne, Matthew
Good on you, but I do have some links in the slides which I will post as soon as I get access to Blackboard.
0:43:34.440 --> 0:43:35.100
Hawthorne, Matthew
Uh.
0:43:36.860 --> 0:43:49.150
Hawthorne, Matthew
I I do have some some references there to the works that we will be more or less discussing, but mostly I give those to you so that you all can engage in some Wikipedia Foo.
0:43:50.60 --> 0:44:2.260
Hawthorne, Matthew
You know, there's a lot of value, especially if if this is just like a a side thing for you and not your career, there's a lot of value to just looking up ethics on Wikipedia and getting caught in an ethical loop in the Wikipedia loop.
0:44:3.670 --> 0:44:10.830
Hawthorne, Matthew
What I do want you to read though is on this page I've got in in front of you.
0:44:10.840 --> 0:44:14.750
Hawthorne, Matthew
I've got 3 links to really good sources.
0:44:15.220 --> 0:44:17.960
Hawthorne, Matthew
The first one is the Internet and cyclopedia of philosophy.
0:44:18.570 --> 0:44:19.220
Hawthorne, Matthew
Umm.
0:44:19.770 --> 0:44:26.340
Hawthorne, Matthew
And this is a very accessible investigation, a very accessible write up about philosophy.
0:44:26.550 --> 0:44:31.180
Hawthorne, Matthew
It's out of a Tennessee University, University of Tennessee at Memphis.
0:44:32.50 --> 0:44:32.860
Hawthorne, Matthew
Really accessible?
0:44:33.410 --> 0:44:46.650
Hawthorne, Matthew
Umm, not that deep, but that's OK because it gives you a lot of stuff in it in a way that I found like really useful to people that aren't like again, making their academic career the study of ethics.
0:44:47.80 --> 0:44:56.170
Hawthorne, Matthew
I also linked to you, the Stanford and Cyclopedia philosophy, which is the exact opposite of the Internet Encyclopedia of Philosophy at the University of Tennessee, Memphis.
0:44:56.600 --> 0:45:11.500
Hawthorne, Matthew
The Stanford Encyclopedia of Philosophy isn't as well laid out, but if you if you spend some time with it, there's a lot of really good stuff there and it's definitely worth at least doing some quick searches, maybe look up Aristotle, cont and Mills.
0:45:11.510 --> 0:45:12.400
Hawthorne, Matthew
You know JS mills.
0:45:14.490 --> 0:45:22.420
Hawthorne, Matthew
I do want you to spend some time on those before our ethical class so that you can at least be familiar with the systems we're going to talk about.
0:45:22.430 --> 0:45:27.380
Hawthorne, Matthew
And again, erisos, Nick and McCain ethics cons Deonte categorical imperatives.
0:45:27.590 --> 0:45:30.500
Hawthorne, Matthew
John Stuart Mills formulation of utilitarianism.
0:45:31.310 --> 0:45:45.380
Hawthorne, Matthew
The one that I really want you to read though is the ACM Code of Ethics and the case scenarios we cover that in the second class of the ethics block and those ones I want you to read all of the code of ethics isn't that long.
0:45:45.660 --> 0:45:52.950
Hawthorne, Matthew
It's only four sections and the 4th section is like 2 paragraphs, but that is the ACM Code of Ethics and it's pretty.
0:45:54.770 --> 0:45:56.0
Hawthorne, Matthew
It's not widely adopted.
0:45:56.10 --> 0:45:59.940
Hawthorne, Matthew
We'll talk about the lack of an option of a code of ethics and the computer engineering profession.
0:46:0.290 --> 0:46:2.700
Hawthorne, Matthew
UM, but it's fairly widely adopted.
0:46:2.710 --> 0:46:12.820
Hawthorne, Matthew
It's well written and the case studies that they have are well, if you look at them, it'll basically tell you how to answer a large part of the ethics test.
0:46:12.970 --> 0:46:13.740
Hawthorne, Matthew
So please do so.
0:46:15.730 --> 0:46:23.710
Hawthorne, Matthew
But they're really good, you know, just little studies about applying the ACM Code of Ethics to the computer engineering profession.
0:46:23.720 --> 0:46:37.260
Hawthorne, Matthew
And some of them are situations that I've actually seen in real life, so I highly recommend it, and that is that so questions, comments, thoughts, leomon, me folks.
0:46:37.450 --> 0:46:38.910
Hawthorne, Matthew
And if you don't have any, not a problem.
0:46:49.420 --> 0:46:57.10
Hawthorne, Matthew
I do want to mention I will get that I will get the discussion prompt posted as soon as I get access to this semester's blackboard again.
0:46:58.410 --> 0:47:0.890
Hawthorne, Matthew
Things have gone funky, but you know such as life.
0:47:6.750 --> 0:47:8.860
Hawthorne, Matthew
Any challenges or here we go.
0:47:8.870 --> 0:47:11.240
Hawthorne, Matthew
Sean, how do you feel about mastering others of strength?
0:47:11.250 --> 0:47:13.880
Hawthorne, Matthew
Mastering yourself. Those who speak.
0:47:14.470 --> 0:47:23.140
Hawthorne, Matthew
I I recognize that quote so that that's a pretty excellent formulation and of a part of Daoist ethics.
0:47:23.150 --> 0:47:28.320
Hawthorne, Matthew
I will say the Dao de Ching is really difficult to get into.
0:47:28.870 --> 0:47:42.920
Hawthorne, Matthew
The Cheng Su and the etching I think are better, especially the etching is a better way to dive into Daoist ethics, but the whole goal of Dawes ethics is self mastery.
0:47:43.570 --> 0:47:45.880
Hawthorne, Matthew
Joseph, there is no due date.
0:47:45.890 --> 0:47:48.650
Hawthorne, Matthew
Just finish it before the end of the semester.
0:47:51.180 --> 0:48:8.380
Hawthorne, Matthew
And the the other thing that that was that's really has is an emphasis on the development of wisdom and the idea that you, when you're wise, you do the wise man makes things happen without making things without doing things.
0:48:8.390 --> 0:48:10.360
Hawthorne, Matthew
They guide people to do things.
0:48:10.870 --> 0:48:13.180
Hawthorne, Matthew
So you don't have to speak really.
0:48:13.510 --> 0:48:22.460
Hawthorne, Matthew
You know, you just it it get the whole the whole concept of Wuwei action within action is really difficult, but it's kind of cool.
0:48:25.880 --> 0:48:30.950
Hawthorne, Matthew
Andy, that is an excellent summation that that is this class summed up in four points.
0:48:35.230 --> 0:48:35.590
Hawthorne, Matthew
But yeah.
0:48:39.600 --> 0:48:48.970
Hawthorne, Matthew
So Richard, I'm when I say that you're Richard asking when I say people use many ethical lenses, you know, I'm talking about major ethical frameworks or, for instance, personal, professional, legal.
0:48:49.270 --> 0:48:51.330
Hawthorne, Matthew
And the answer to that is all of them.
0:48:51.740 --> 0:49:1.830
Hawthorne, Matthew
Most people, I really do think that most people, when they make decisions, they use a combination of all of the ethics that they picked up right?
0:49:1.920 --> 0:49:16.900
Hawthorne, Matthew
A devout Christian is going to make should be making ethical decisions based on the ethics found in the New Testament, you know, but they're also going to do so in light of the ethics that they've picked up and learned about their profession.
0:49:17.370 --> 0:49:23.120
Hawthorne, Matthew
You know about individual things that they've learned in the course of their personal lives.
0:49:23.170 --> 0:49:32.30
Hawthorne, Matthew
You know it's going to color how they apply this to everything, and most people will act at least with an eye towards what's legal, cause most people don't want to go to jail.
0:49:33.440 --> 0:49:50.150
Hawthorne, Matthew
So you know and and that applies to everything like when you all when you all make a decision about whether or not to come to class, which is really low level decision, right, there's not necessarily a whole lot of ethical implications in that, but every decision is an ethical decision.
0:49:50.640 --> 0:50:1.530
Hawthorne, Matthew
OK, when you all make that decision about whether or not you're gonna come to class, you're making that decision based on a huge variety of ethical principles that you maybe aren't even thinking about.
0:50:1.600 --> 0:50:6.480
Hawthorne, Matthew
You know, maybe you decide to come to class because you want to be the sort of student that goes to class.
0:50:6.850 --> 0:50:12.180
Hawthorne, Matthew
Maybe you decide to come to class because you're worried that if you don't come to class, you're gonna get marked off on participation points.
0:50:12.690 --> 0:50:26.760
Hawthorne, Matthew
Maybe you don't go to class because you've got half a dozen much more serious projects and having an hour and a half back into your life is going to help you finish those up, which is going to do better for your grade, which is a personal consequentialist view, right?
0:50:26.850 --> 0:50:34.60
Hawthorne, Matthew
Most people make those sorts of decisions with a like I said, a web of unexamined ethical ideas.
0:50:37.640 --> 0:50:37.970
Hawthorne, Matthew
Uh.
0:50:37.980 --> 0:50:40.410
Hawthorne, Matthew
Alex asked with professional ethical codes.
0:50:40.420 --> 0:50:42.160
Hawthorne, Matthew
Is it up to some counsel to decide?
0:50:43.580 --> 0:50:45.190
Hawthorne, Matthew
Yeah, usually.
0:50:45.860 --> 0:50:49.90
Hawthorne, Matthew
You know, usually it's some governing body.
0:50:49.800 --> 0:51:3.410
Hawthorne, Matthew
Oftentimes that has been established by tradition or by some sort of the election process, or sometimes just a bunch of people that get together and are like, hey, we think this and other people buy into it and they had then have the authority to do that.
0:51:5.80 --> 0:51:10.590
Hawthorne, Matthew
So yeah, that what you say at the end, you know it's brought up in just accepted by society as a whole.
0:51:10.620 --> 0:51:11.730
Hawthorne, Matthew
Is kind of accurate.
0:51:12.640 --> 0:51:13.230
Hawthorne, Matthew
That's the.
0:51:13.240 --> 0:51:17.560
Hawthorne, Matthew
That's the social contract really, which would be a topic unto itself.
0:51:22.970 --> 0:51:23.620
Hawthorne, Matthew
That's a good question.
0:51:29.210 --> 0:51:30.810
Hawthorne, Matthew
Nicholas, that's a good question.
0:51:30.820 --> 0:51:33.380
Hawthorne, Matthew
Do I have any thoughts on Stoicism versus Epicureanism?
0:51:33.970 --> 0:51:35.820
Hawthorne, Matthew
Epicureanism gets a bad rap.
0:51:36.480 --> 0:51:40.220
Hawthorne, Matthew
I actually think Stoicism and Epicureanism are two sides of the same coin.
0:51:40.510 --> 0:51:41.600
Hawthorne, Matthew
I prefer stoicism.
0:51:42.610 --> 0:51:52.680
Hawthorne, Matthew
Umm, but that's mostly because Marcus Aurelius's meditations is basically a if I have any Brandon Sanderson fans in here, it's basically a real life way of kings.
0:51:53.250 --> 0:51:56.460
Hawthorne, Matthew
It is a dude who is doing his best to live an ethical life.
0:51:59.20 --> 0:52:3.410
Hawthorne, Matthew
Writing journaling his thoughts about how to do so, and it's super accessible.
0:52:4.380 --> 0:52:17.510
Hawthorne, Matthew
The other thing is Stoicism kind of has a really strong emphasis on tenacity, which is also shared by Daoism, by the way, perseverance would be more the Daoist terminology.
0:52:18.400 --> 0:52:21.500
Hawthorne, Matthew
And honestly, you know, grit matters.
0:52:22.800 --> 0:52:32.620
Hawthorne, Matthew
Umm, so I tend to prefer Stoicism, but I actually think Stoicism and Epicureanism arrive at the same point through different pathways by Jay Phillip, my peeps.
0:52:36.470 --> 0:52:37.470
Hawthorne, Matthew
OK, I can see that Nicholas.
0:52:43.540 --> 0:52:44.530
Hawthorne, Matthew
I can definitely see that.
0:52:44.790 --> 0:52:46.360
Hawthorne, Matthew
How do I feel about existentialism?
0:52:47.960 --> 0:52:54.750
Hawthorne, Matthew
Man, so I actually read a decent amount of existentialism in college and it just it never really clicked with me.
0:52:56.310 --> 0:53:0.160
Hawthorne, Matthew
A lot of the postmodern philosophies just don't click with me.
0:53:2.410 --> 0:53:9.840
Hawthorne, Matthew
But that's not because I think they're wrong as much as it's just like I mentioned earlier, I was raised really old school in this regard.
0:53:10.320 --> 0:53:18.640
Hawthorne, Matthew
Umm, I think there's a lot of value in the idea that existence has the meaning that we give it.
0:53:19.950 --> 0:53:20.470
Hawthorne, Matthew
Umm.
0:53:20.550 --> 0:53:28.370
Hawthorne, Matthew
And I think, especially if you're trying to have a more humanist approach to ethics, that's almost required.
0:53:30.750 --> 0:53:44.650
Hawthorne, Matthew
You you almost have to accept that the only meaning to existence is the meaning that we give it, and that's what allows you to then create ethical rules for yourself to follow.
0:53:47.200 --> 0:53:48.70
Hawthorne, Matthew
Where?
0:53:48.320 --> 0:53:58.430
Hawthorne, Matthew
But the issue with the issue with the with existentialism and knee chain particular is the tendency towards solipsism and solipsism.
0:53:58.480 --> 0:54:4.380
Hawthorne, Matthew
Is, I think, a A, a it it it's it's a fault.
0:54:4.740 --> 0:54:6.920
Hawthorne, Matthew
It's not a, it's not.
0:54:7.300 --> 0:54:7.910
Hawthorne, Matthew
It's not.
0:54:8.20 --> 0:54:9.260
Hawthorne, Matthew
It's it's not a feature, it's a bug.
0:54:9.980 --> 0:54:15.990
Hawthorne, Matthew
Umm, I don't think the same thing about nihilism necessarily, but I do think that about solipsism.
0:54:16.780 --> 0:54:19.260
Hawthorne, Matthew
Umm, ethics is the trolley problem?
0:54:19.270 --> 0:54:21.820
Hawthorne, Matthew
No, clay ethics is not the trolley problem.
0:54:23.190 --> 0:54:27.920
Hawthorne, Matthew
I don't like the trolley problem because it's a little too far removed from.
0:54:30.250 --> 0:54:39.0
Hawthorne, Matthew
From real life to actually teach people anything, I think if you're really interested in the trolley problem, you do a better job studying Buddhism and then looking up some Zen coins.
0:54:42.140 --> 0:54:48.630
Hawthorne, Matthew
I think there are variations of the trolley problem that can be useful, but the trolley problem in and of itself is it.
0:54:49.0 --> 0:54:50.370
Hawthorne, Matthew
I get why it's there.
0:54:50.380 --> 0:54:51.810
Hawthorne, Matthew
I get it's a teaching tool.
0:54:51.820 --> 0:54:55.970
Hawthorne, Matthew
It's just not one I like Austin asked about absurdism.
0:54:55.980 --> 0:55:3.90
Hawthorne, Matthew
In our modern society, some days it feels like that's the only real response to what our modern society is.
0:55:3.860 --> 0:55:9.300
Hawthorne, Matthew
But again, most of my study and ethics is old, not new.
0:55:9.900 --> 0:55:11.940
Hawthorne, Matthew
Most of my study in philosophy is old, not new.
0:55:14.370 --> 0:55:18.690
Hawthorne, Matthew
How often are the reading assignments going to come up in class compared to just the discussion board?
0:55:19.390 --> 0:55:26.60
Hawthorne, Matthew
So for the ethics portion, we will talk about uh aristotles Megan McCain.
0:55:26.70 --> 0:55:28.780
Hawthorne, Matthew
Ethics constitute categorical imperatives and mills.
0:55:28.790 --> 0:55:35.290
Hawthorne, Matthew
Utilitarianism on the 1st Ethics Day and we'll talk about the ACM Code of Ethics and the cases on the second Ethics day, and then they'll never pop up again.
0:55:35.770 --> 0:55:43.690
Hawthorne, Matthew
Umm, but the discussion board will deal with them for the copyright section when I give you the reasons on them, the class is taught on the reading assignments.
0:55:45.900 --> 0:55:51.430
Hawthorne, Matthew
Some of the worst hypothetical decisions that can't mill, etcetera would make face on their ideas.
0:55:51.440 --> 0:55:53.80
Hawthorne, Matthew
Nicholas, I have never had anyone.
0:55:55.70 --> 0:55:56.940
Hawthorne, Matthew
I've never had anyone ask me that question before.
0:55:57.0 --> 0:55:58.420
Hawthorne, Matthew
That's one I'd have to think about?
0:55:58.490 --> 0:55:59.100
Hawthorne, Matthew
Richard asked.
0:55:59.110 --> 0:56:1.960
Hawthorne, Matthew
Can you step back and explain the difference between Nehalem and solipsism?
0:56:2.370 --> 0:56:6.680
Hawthorne, Matthew
Nihilism is the belief that nothing really matters, and solipsism is the belief that only you matter.
0:56:7.310 --> 0:56:19.60
Hawthorne, Matthew
One of those is both of those I think are flawed, but nihilism isn't fundamentally flawed, because if nothing really matters, then everything has the has the value that is given to it.
0:56:19.130 --> 0:56:28.260
Hawthorne, Matthew
It doesn't have intrinsic value, so lips ISM is the idea that only you matter and that leads to like the worst case is the main character syndrome you will ever see.
0:56:28.830 --> 0:56:30.740
Hawthorne, Matthew
That's when you get people who start.
0:56:31.340 --> 0:56:34.470
Hawthorne, Matthew
I mean that that's when things get bad.
0:56:38.950 --> 0:56:40.940
Hawthorne, Matthew
Ascribed value based on circumstance.
0:56:40.950 --> 0:56:42.630
Hawthorne, Matthew
Yeah, there's some accuracy to that.
0:56:47.890 --> 0:56:57.230
Hawthorne, Matthew
I think you can have a valid ethical theory with things not having intrinsic value which is at its core what nihilism is.
0:56:58.120 --> 0:57:5.350
Hawthorne, Matthew
I don't think you can have a valid ethical theory when you're fundamental proposition is the only thing that has intrinsic value is yourself.
0:57:19.480 --> 0:57:21.200
Hawthorne, Matthew
And y'all asking good questions to day.
0:57:22.460 --> 0:57:24.890
Hawthorne, Matthew
Now again, Richard, that's my thoughts on the matter.
0:57:25.300 --> 0:57:32.290
Hawthorne, Matthew
You know, if you asked if you ask five different philosophers to same question, you'd probably get like 13 different answers. Sean.
0:57:32.300 --> 0:57:34.750
Hawthorne, Matthew
Yeah, that's that's my thought on it.
0:57:34.760 --> 0:57:41.570
Hawthorne, Matthew
But again, you know my fundamental ethical theory is, though ISM and Stoicism is actually very externally focused.
0:57:42.100 --> 0:57:49.390
Hawthorne, Matthew
Buddhism and Stoicism are like the two things that I try to live by, you know, and there's a reason I like ethics of care.
0:57:49.700 --> 0:57:50.760
Hawthorne, Matthew
The world sucks.
0:57:50.880 --> 0:57:53.190
Hawthorne, Matthew
Don't make things worse for people, right?
0:57:56.60 --> 0:57:57.360
Hawthorne, Matthew
I don't actually think the world sucks.
0:57:57.370 --> 0:57:58.400
Hawthorne, Matthew
I just think it's hard.
0:57:58.880 --> 0:57:59.980
Hawthorne, Matthew
Life is hard.
0:58:0.80 --> 0:58:2.330
Hawthorne, Matthew
Don't make things bad for other people you know.
0:58:5.500 --> 0:58:7.240
Hawthorne, Matthew
Yeah, Joey, that's basically it.
0:58:7.810 --> 0:58:13.620
Hawthorne, Matthew
Umm can you apply it on a broad range without causing large problems?
0:58:13.630 --> 0:58:22.280
Hawthorne, Matthew
Large amounts of harm if you can't universally apply something without causing like large amounts of harm, it's probably not a valid ethical theory.
0:58:22.750 --> 0:58:24.270
Hawthorne, Matthew
You know umm.
0:58:24.280 --> 0:58:27.90
Hawthorne, Matthew
And again, you still have to answer what constitutes harm.
0:58:27.100 --> 0:58:28.450
Hawthorne, Matthew
You can dive down that whole.
0:58:28.630 --> 0:58:39.720
Hawthorne, Matthew
You know that rabbit hole for ages, but fundamental end of the day if you can't apply your theory without, you know, just mucking up everybody's lives, it's not a valid ethical theory.
0:58:41.820 --> 0:58:44.520
Hawthorne, Matthew
As long as it's a peaceful anarchy, you're not wrong, Robert.
0:58:45.540 --> 0:58:47.670
Hawthorne, Matthew
If it was a peaceful anarchy, that might be ideal.
0:58:50.690 --> 0:58:54.600
Hawthorne, Matthew
OK, Richard, the highest common good is the best pursuit for any given individual.
0:58:55.520 --> 0:58:57.220
Hawthorne, Matthew
That's kind of like the Objectivist.
0:58:57.270 --> 0:59:2.830
Hawthorne, Matthew
The Anne Rand viewpoint and the problem with that is in general it never works that way.
0:59:3.950 --> 0:59:4.370
Hawthorne, Matthew
OK.
0:59:4.510 --> 0:59:14.40
Hawthorne, Matthew
If you act entirely self-centered, pursuing only your best common good, you're not acting with regard to the impact on other people.
0:59:14.170 --> 0:59:19.840
Hawthorne, Matthew
And again, we live in a society fundamental principle of Buddhism is everything is connected.
0:59:20.330 --> 0:59:23.420
Hawthorne, Matthew
You know the intricate web of interdependence.
0:59:23.800 --> 0:59:26.560
Hawthorne, Matthew
You know the actions that you take effect others.
0:59:28.330 --> 0:59:31.970
Hawthorne, Matthew
Both both other individuals, but also just the world around you.
0:59:33.180 --> 0:59:33.830
Hawthorne, Matthew
OK.
0:59:33.930 --> 0:59:36.340
Hawthorne, Matthew
And that's part of why study of ethics is so important.
0:59:36.450 --> 0:59:37.890
Hawthorne, Matthew
Because you wanna take good actions.
0:59:37.970 --> 0:59:46.770
Hawthorne, Matthew
So you can make your lives and everybody's lives a little bit better, so anything that goes against that in my mind is pretty invalid.
0:59:47.200 --> 0:59:47.730
Hawthorne, Matthew
This is the way.
0:59:53.180 --> 0:59:59.790
Hawthorne, Matthew
Yes, Nicholas Cont would not lie even if it saves 1,000,000 lives because absolute honesty was one of his categorical imperatives.
1:0:3.860 --> 1:0:7.490
Hawthorne, Matthew
Mill probably would enslave one person to make everyone have good lives.
1:0:7.500 --> 1:0:9.280
Hawthorne, Matthew
Mill probably would come down on.
1:0:9.290 --> 1:0:13.110
Hawthorne, Matthew
You could kill a dude if doing so would save enough other people.
1:0:13.660 --> 1:0:15.860
Hawthorne, Matthew
I think if you really pushed him on that he would do so.
1:0:16.680 --> 1:0:19.170
Hawthorne, Matthew
UM and Nicholas I also agree with you.
1:0:19.180 --> 1:0:22.710
Hawthorne, Matthew
I do think virtue ethics is the most resilient to those extreme hypotheticals.
1:0:22.860 --> 1:0:24.870
Hawthorne, Matthew
It just has its own problems as well.
1:0:25.260 --> 1:0:30.730
Hawthorne, Matthew
Yes, Ben, there's a lot you can learn from verbal virtue ethics from comic books.
1:0:33.590 --> 1:0:34.520
Hawthorne, Matthew
Ohh Richard.
1:0:34.530 --> 1:0:35.600
Hawthorne, Matthew
OK, I see what you mean.
1:0:35.610 --> 1:0:42.180
Hawthorne, Matthew
I I thought you were saying the opposite of it, that the pursuit of what's best for you is what's best for everybody.
1:0:43.650 --> 1:0:45.860
Hawthorne, Matthew
Now you gotta be careful with what you're saying, Richard.
1:0:45.870 --> 1:0:53.400
Hawthorne, Matthew
Because, umm, you know, you you run into the giving tree problem right where you give and give and give and give and you don't.
1:0:53.410 --> 1:0:55.280
Hawthorne, Matthew
You know, you gotta take care of yourself too.
1:0:55.320 --> 1:1:0.800
Hawthorne, Matthew
One of the fundamental principles of ethics of care is you have to take care of yourself in order to take care of others.
1:1:1.830 --> 1:1:11.110
Hawthorne, Matthew
But I do think that acting with an eye towards the greater good is a fundamentally ethic ethical at ethical viewpoint.
1:1:13.120 --> 1:1:15.490
Hawthorne, Matthew
But again, these are my thoughts on the matter.
1:1:15.840 --> 1:1:21.630
Hawthorne, Matthew
You know, you go, makes you go do your own reading, and you're gonna find a whole bunch of people that have entirely different thoughts on the matter.
1:1:24.250 --> 1:1:25.310
Hawthorne, Matthew
Alright so.
1:1:28.90 --> 1:1:29.640
Hawthorne, Matthew
I'm going to stop the recording.
1:1:29.810 --> 1:1:31.140
Hawthorne, Matthew
Ohh, I can't stop the recording.
1:1:31.180 --> 1:1:33.0
Hawthorne, Matthew
Robert, do you mind stopping the recording?
1:1:33.470 --> 1:1:34.920
Hawthorne, Matthew
Thank you for starting that up by the way.
1:1:34.930 --> 1:1:35.750
Hawthorne, Matthew
I really appreciate it.
